import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import torch

# load data
df = pd.read_csv("final_dataset.csv")

# remove extreme values
df = df[(df['fire_weather_index'] >= 0) & (df['fire_weather_index'] < 60)]

# create risk labels based on occurred and FWI
def risk_label(row):
    if row['occured'] == 1 or row['fire_weather_index'] > 30:
        return 2
    elif row['fire_weather_index'] >= 10:
        return 1
    else:
        return 0

df['risk_level'] = df.apply(risk_label, axis=1)

# split features/labels
X = df.drop(columns=['risk_level', 'occured'])
y = df['risk_level']

# split data
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)

# normalize
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

# convert tensors
X_train_t = torch.tensor(X_train, dtype=torch.float32)
y_train_t = torch.tensor(y_train.values, dtype=torch.long)
X_val_t = torch.tensor(X_val, dtype=torch.float32)
y_val_t = torch.tensor(y_val.values, dtype=torch.long)
X_test_t = torch.tensor(X_test, dtype=torch.float32)
y_test_t = torch.tensor(y_test.values, dtype=torch.long)
